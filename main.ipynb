{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference https://www.kaggle.com/code/quang7doan/unet-doi-train-test-them-metric\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "import csv\n",
    "\n",
    "# import cv2\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from glob import glob\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from skimage.color import rgb2gray\n",
    "from tensorflow.keras.models import Model, load_model, save_model\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR) #to hide the autigraph WARNING at model.fit\n",
    "from random import random,randrange\n",
    "from operator import itemgetter\n",
    "import timeit\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid, ParameterSampler\n",
    "from Unet import unet_model\n",
    "from Irnet import conv_irnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Parameters\n",
    "im_width = 256\n",
    "im_height = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = []\n",
    "mask_files = glob('./data/input/lgg-mri-segmentation/kaggle_3m/*/*_mask*')\n",
    "\n",
    "for i in mask_files:\n",
    "    train_files.append(i.replace('_mask',''))\n",
    "\n",
    "# print(train_files[:10])\n",
    "# print(mask_files[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows,cols=3,3\n",
    "fig=plt.figure(figsize=(10,10))\n",
    "for i in range(1,rows*cols+1):\n",
    "    fig.add_subplot(rows,cols,i)\n",
    "    img_path=train_files[i]\n",
    "    msk_path=mask_files[i]\n",
    "    img=plt.imread(img_path)\n",
    "    # img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    msk=plt.imread(msk_path)\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(msk,alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"filename\": train_files, 'mask' : mask_files})\n",
    "df_train, df_test = train_test_split(df,test_size = 0.15)\n",
    "df_train, df_val = train_test_split(df_train,test_size = 0.1765)\n",
    "print(df_train.values.shape)\n",
    "print(df_val.values.shape)\n",
    "print(df_test.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(data_frame, batch_size, aug_dict,\n",
    "        image_color_mode=\"rgb\",\n",
    "        mask_color_mode=\"grayscale\",\n",
    "        image_save_prefix=\"image\",\n",
    "        mask_save_prefix=\"mask\",\n",
    "        save_to_dir=None,\n",
    "        target_size=(256,256),\n",
    "        seed=1):\n",
    "    '''\n",
    "    can generate image and mask at the same time use the same seed for\n",
    "    image_datagen and mask_datagen to ensure the transformation for image\n",
    "    and mask is the same if you want to visualize the results of generator,\n",
    "    set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    image_datagen = ImageDataGenerator(**aug_dict)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
    "    \n",
    "    image_generator = image_datagen.flow_from_dataframe(\n",
    "        data_frame,\n",
    "        x_col = \"filename\",\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        seed = seed)\n",
    "\n",
    "    mask_generator = mask_datagen.flow_from_dataframe(\n",
    "        data_frame,\n",
    "        x_col = \"mask\",\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        seed = seed)\n",
    "\n",
    "    train_gen = zip(image_generator, mask_generator)\n",
    "    \n",
    "    for (img, mask) in train_gen:\n",
    "        img, mask = adjust_data(img, mask)\n",
    "        yield (img,mask)\n",
    "\n",
    "def adjust_data(img,mask):\n",
    "    img = img / 255\n",
    "    mask = mask / 255\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask <= 0.5] = 0\n",
    "    \n",
    "    return (img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth=100\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_truef=K.flatten(y_true)\n",
    "    y_predf=K.flatten(y_pred)\n",
    "    And=K.sum(y_truef* y_predf)\n",
    "    return((2* And + smooth) / (K.sum(y_truef) + K.sum(y_predf) + smooth))\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    sum_ = K.sum(y_true + y_pred)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return jac\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data is ready for training/testing, Random Grid Search:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA/TASK INFORMATION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DATA/TASK INFORMATION:\n",
    "architecture_name=\"unet\"\n",
    "problem_type=\"segmentation\"\n",
    "num_features=df_train.shape\n",
    "input_shape =(im_height,im_width,3)\n",
    "model_file_name=architecture_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RGS evaluate_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fitness(input_shape,n_layers,activation_function,learning_rate,batch_size,hp_dataset_name,weights_name,max_epochs,patience_epochs):\n",
    "    clear_session()\n",
    "    EPOCHS = max_epochs\n",
    "    len(df_val)/batch_size\n",
    "    #callbacks\n",
    "    earlystopping = EarlyStopping(monitor='val_loss',\n",
    "                              mode='min', \n",
    "                                verbose=1, \n",
    "                                patience=patience_epochs\n",
    "                                )\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                mode='min',\n",
    "                                verbose=1,\n",
    "                                patience=10,\n",
    "                                min_delta=0.0001,\n",
    "                                factor=0.2\n",
    "                                )\n",
    "    #augmentate training data\n",
    "    train_generator_args = dict(rotation_range=0.2,\n",
    "                                width_shift_range=0.05,\n",
    "                                height_shift_range=0.05,\n",
    "                                shear_range=0.05,\n",
    "                                zoom_range=0.05,\n",
    "                                horizontal_flip=True,\n",
    "                                fill_mode='nearest')\n",
    "\n",
    "    train_gen = train_generator(df_train, batch_size,\n",
    "                                    train_generator_args,\n",
    "                                    target_size=(im_height, im_width))\n",
    "    #augmentate valid data\n",
    "    val_gener = train_generator(df_val, batch_size,\n",
    "                                    dict(),\n",
    "                                    target_size=(im_height, im_width))\n",
    "    #create the model\n",
    "    model=unet_model(input_shape,n_layers,activation_function,learning_rate)\n",
    "    callbacks = [ModelCheckpoint('data/checkpoints/'+model_file_name+'.hdf5', verbose=1, save_best_only=True), earlystopping,reduce_lr]\n",
    "    start_time = timeit.default_timer()\n",
    "    history = model.fit(train_gen,\n",
    "                    steps_per_epoch=len(df_train) / batch_size, \n",
    "                    epochs=EPOCHS, \n",
    "                    callbacks=callbacks,\n",
    "                    validation_data = val_gener,\n",
    "                    validation_steps=len(df_val) / batch_size)\n",
    "    \n",
    "    end_time = timeit.default_timer()\n",
    "    training_and_validation_samples=len(df_train)+len(df_val)\n",
    "    print(\"==== len train valid data\",len(df_train),len(df_val))\n",
    "    #EVALUATE MODEL\n",
    "    test_gen = train_generator(df_test, 32,\n",
    "                                    dict(),\n",
    "                                    target_size=(im_height, im_width))\n",
    "    results = model.evaluate(test_gen, steps=len(df_test) / 32)\n",
    "    print(\"Test IOU: \",results[2])\n",
    "    iou_test=results[2]\n",
    "\n",
    "    #SAVE THE WEIGHTS\n",
    "    model.save(\"data/weights/\"+architecture_name+\"/\"+weights_name+\".h5\")\n",
    "    #SAVE THE HYPERPARAMS AND THE METRIC\n",
    "    with open('data/'+hp_dataset_name, mode='a+') as hp_dataset:\n",
    "        hp_dataset_writer=csv.writer(hp_dataset,delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        hp_dataset_writer.writerow([architecture_name,\n",
    "                                problem_type,\n",
    "                                num_features,\n",
    "                                training_and_validation_samples,\n",
    "                                n_layers,\n",
    "                                input_shape,\n",
    "                                activation_function,\n",
    "                                learning_rate,\n",
    "                                batch_size,\n",
    "                                str(len(history.history['loss'])),\n",
    "                                end_time-start_time,\n",
    "                                iou_test\n",
    "                                ])\n",
    "    return iou_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RGS main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_gridsearch(population_size,input_shape,n_layers,activation_function,learning_rate,batch_size,hp_dataset_name,max_epochs,patience_epochs):\n",
    "        dict_all_hyperparams=dict(n_layers=n_layers,\n",
    "                                learning_rate=learning_rate,\n",
    "                                activation_function=activation_function,\n",
    "                                batch_size=batch_size,\n",
    "                                )\n",
    "        r_grid_search_population=list(ParameterSampler(dict_all_hyperparams,population_size))\n",
    "        \n",
    "        RGS_evaluated_hparams=[]\n",
    "        with open(\"data/logs/Logs_RandomGridSearch.csv\", mode='a+') as logs_dataset:\n",
    "                logs_dataset_writer=csv.writer(logs_dataset,delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                logs_dataset_writer.writerow([\"population: \"+str(population_size)])\n",
    "                logs_dataset_writer.writerows(dict(x=r_grid_search_population).values())\n",
    "        print(r_grid_search_population)\n",
    "\n",
    "        \n",
    "        for i in range(len(r_grid_search_population)):\n",
    "                weights_name='{}-{}-{}-{}'.format(r_grid_search_population[i]['n_layers'],r_grid_search_population[i]['activation_function'],r_grid_search_population[i]['learning_rate'],r_grid_search_population[i]['batch_size'])\n",
    "                model_file_name=architecture_name+str(i)\n",
    "                metric=evaluate_fitness(input_shape,\n",
    "                                r_grid_search_population[i]['n_layers'],\n",
    "                                r_grid_search_population[i]['activation_function'],\n",
    "                                r_grid_search_population[i]['learning_rate'],\n",
    "                                r_grid_search_population[i]['batch_size'],\n",
    "                                hp_dataset_name,\n",
    "                                weights_name,\n",
    "                                max_epochs,\n",
    "                                patience_epochs\n",
    "                                )\n",
    "                \n",
    "                with open(\"data/logs/Logs_RandomGridSearch.csv\", mode='a+') as logs_dataset:\n",
    "                        logs_dataset_writer=csv.writer(logs_dataset,delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                        logs_dataset_writer.writerow([\"i:\"+str(i)+\"Metric:\"+str(metric)])\n",
    "                print(\"i\",i,\"Mae:\",metric)\n",
    "\n",
    "                RGS_evaluated_hparams.insert(len(RGS_evaluated_hparams),{\"hparam\":i,\"metric\":metric})\n",
    "        rgs_top_hparam=sorted(RGS_evaluated_hparams,key=itemgetter('metric'),reverse=True)[0]['hparam']\n",
    "        \n",
    "        with open(\"data/logs/Logs_RandomGridSearch.csv\", mode='a+') as logs_dataset:\n",
    "                        logs_dataset_writer=csv.writer(logs_dataset,delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                        logs_dataset_writer.writerow(\"END\")\n",
    "                        logs_dataset_writer.writerows(sorted(RGS_evaluated_hparams,key=itemgetter('metric'),reverse=True)[0]['metric'],r_grid_search_population[rgs_top_hparam])\n",
    "        \n",
    "        return sorted(RGS_evaluated_hparams,key=itemgetter('metric'),reverse=True)[0]['metric'],r_grid_search_population[rgs_top_hparam]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RGS Definitions and invocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HYPERPARAMETERS DEFINITION\n",
    "n_layers = [1,2,3]\n",
    "activation_function=['relu','tanh','sigmoid','elu']\n",
    "learning_rate=[0.01,0.001,0.0001,0.00001]\n",
    "batch_size=[8,16,32,64]\n",
    "max_epochs=200\n",
    "patience_epochs=20\n",
    "\n",
    "#FILES NAME\n",
    "hp_dataset_name=\"unet_hyperparams_with_metric.csv\"\n",
    "\n",
    "#ALGORITHM PARAMS\n",
    "population_size=30\n",
    "\n",
    "random_gridsearch(population_size,input_shape,n_layers,activation_function,learning_rate,batch_size,hp_dataset_name,max_epochs,patience_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST MODEL\n",
    "\n",
    "# model = load_model(model_name+'.hdf5', custom_objects={'dice_coef_loss': dice_coef_loss, 'iou': iou, 'dice_coef': dice_coef})\n",
    "# # model.summary()\n",
    "# test_gen = train_generator(df_test, 32,\n",
    "#                                 dict(),\n",
    "#                                 target_size=(im_height, im_width))\n",
    "# results = model.evaluate(test_gen, steps=len(df_test) / 32)\n",
    "# print(\"Test IOU: \",results[2])\n",
    "# print(\"Test lost: \",results[0])\n",
    "# print(\"Test Dice Coefficent: \",results[3])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fb98013d4c2891267818ea7c909444c4c0da64618fb7bda0edb10d2c08cfbac9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
